[build-system]
requires = ["setuptools>=78.0.1", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "Crawl4AI"
dynamic = ["version"]
description = "ðŸš€ðŸ¤– Crawl4AI: Open-source LLM Friendly Web Crawler & scraper"
readme = "README.md"
requires-python = ">=3.9"
license = "MIT"
authors = [
    {name = "Unclecode", email = "unclecode@kidocode.com"}
]
dependencies = [
    "aiosqlite~=0.20",
    "lxml~=5.3",
    "litellm>=1.53.1",
    "numpy>=1.26.0,<3",
    "pillow~=10.4",
    "playwright>=1.49.0",
    "python-dotenv~=1.0",
    "requests~=2.26",
    "beautifulsoup4~=4.12",
    "tf-playwright-stealth>=1.1.0",
    "xxhash~=3.4",
    "rank-bm25~=0.2",
    "aiofiles>=24.1.0",
    "colorama~=0.4",
    "snowballstemmer~=2.2",
    "pydantic>=2.10",
    "pyOpenSSL>=24.3.0",
    "psutil>=6.1.1",
    "nltk>=3.9.1",
    "playwright",
    "aiofiles",
    "rich>=13.9.4",
    "cssselect>=1.2.0",
    "httpx>=0.27.2",
    "fake-useragent>=2.0.3",
    "click>=8.1.7",
    "pyperclip>=1.8.2",
    "faust-cchardet>=2.1.19",
    "aiohttp>=3.11.11",
    "humanize>=4.10.0",
    "pdf2image>=1.17.0",
    "bitarray>=3.2.0",
    "mmh3>=5.1.0",
]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
]

[project.optional-dependencies]
pdf = ["PyPDF2", "pdf2image"]
torch = ["torch", "nltk", "scikit-learn"]
transformer = ["transformers", "tokenizers"]
cosine = ["torch", "transformers", "nltk"]
sync = ["selenium"]
all = [
    "crawl4ai[cosine]",
    "crawl4ai[pdf]",
    "crawl4ai[sync]",
    "crawl4ai[torch]",
    "crawl4ai[transformer]",
]

[project.scripts]
crawl4ai-download-models = "crawl4ai.model_loader:main"
crawl4ai-migrate = "crawl4ai.migrations:main"
crawl4ai-setup = "crawl4ai.install:post_install"
crawl4ai-doctor = "crawl4ai.install:doctor"
crwl = "crawl4ai.cli:main"

[tool.setuptools]
packages = {find = {where = ["."], include = ["crawl4ai*"]}}

[tool.setuptools.package-data]
crawl4ai = ["js_snippet/*.js"]

[tool.setuptools.dynamic]
version = {attr = "crawl4ai.__version__.__version__"}

[tool.uv.sources]
crawl4ai = { workspace = true }

[dependency-groups]
dev = [
    "crawl4ai",
]
docker = [
    "fastapi>=0.115.11",
    "redis>=5.2.1",
]
test = [
    "matplotlib>=3.9.4",
    "nest-asyncio>=1.6.0",
    "nltk>=3.9.1",
    "pytest-aiohttp>=1.1.0",
    "pytest-asyncio>=0.25.3",
    "pytest-cov>=6.0.0",
    "pytest-httpserver>=1.1.2",
    "pytest-timeout>=2.3.1",
    "pytest>=8.3.5",
    "scipy>=1.13.1",
    "selenium>=4.29.0",
    "tabulate>=0.9.0",
    "torch>=2.6.0",
    "transformers>=4.49.0",
]

[tool.pytest.ini_options]
asyncio_default_fixture_loop_scope = "function" # Prevent deprecation warning
# Disable deprecation warnings for code we don't control.
filterwarnings = [
    "ignore::DeprecationWarning",
    "default::DeprecationWarning:__main__",
    "default::DeprecationWarning:crawl4ai.*",
]
timeout = 20
timeout_func_only = true

# Basic configuration for the `ruff` tool to preserve basic formatting.
[tool.ruff]
line-length = 120
target-version = "py39"

# As a temporary workaround, exclude all files from ruff formatting as the
# code base has various code style and would introduce a lot of noise.
[tool.ruff.format]
exclude = ["*.py"]
